# CrossLingual-DE-EN-Transformers

This repository contains an implementation of the Transformer architecture from scratch using PyTorch, specifically designed for the task of translating text from German (DE) to English (EN). The model is trained on the widely recognized Multi30k dataset, showcasing the effective use of Transformer models in neural machine translation (NMT).

## Project Overview

The Transformer model, introduced in the paper "Attention is All You Need" by Vaswani et al., has revolutionized the field of natural language processing (NLP) by providing a mechanism for parallelizable processing and long-range dependencies handling in sequence-to-sequence tasks. This project aims to demystify the Transformer architecture by implementing it from the ground up and applying it to a practical translation task.

### Features

- Complete Transformer model implementation in PyTorch.
- Training and evaluation on the Multi30k German-to-English translation dataset.
- Customizable hyperparameters for model experimentation.

